{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "hired-richards",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    div#notebook-container    { width: 95%; }\n",
       "    div#menubar-container     { width: 85%; }\n",
       "    div#maintoolbar-container { width: 99%; }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 85%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "from scipy.stats import uniform\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_validate, cross_val_score, cross_val_predict, GridSearchCV, RandomizedSearchCV, KFold, StratifiedKFold, validation_curve\n",
    "from sklearn.pipeline import Pipeline as Pipeline, make_pipeline as make_pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.utils import resample\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, SMOTENC\n",
    "from imblearn.under_sampling import NearMiss, RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline as Imbpipeline\n",
    "from imblearn.pipeline import make_pipeline as Imb_make_pipeline\n",
    "\n",
    "from imblearn.combine import SMOTETomek, SMOTEENN\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "df_data_set = pd.read_csv(r'C:\\Users\\moham\\Dropbox\\QSE\\Thesis\\Geopattern\\My data\\df_data_set_North_America.csv')\n",
    "\n",
    "df_data_set['Log_TENB'] = df_data_set.TENB.apply(lambda x :math.log1p(x))\n",
    "df_data_set['Log_Geo_Dist X Log_TENB'] = df_data_set['Log_Geo_Dist'] * df_data_set['Log_TENB']\n",
    "df_data_set['Log_Geo_Dist_Sq'] = df_data_set['Log_Geo_Dist'] * df_data_set['Log_Geo_Dist']\n",
    "df_data_set['Log_Geo_Dist_Sq X Log_TENB'] = df_data_set['Log_Geo_Dist_Sq'] * df_data_set['Log_TENB']\n",
    "\n",
    "df_data_set['Log_Geo_Dist X Cog_Dist'] = df_data_set['Log_Geo_Dist'] * df_data_set['Cog_Dist']\n",
    "\n",
    "df_data_set['Prov_Border X Log_TENB'] = df_data_set['Prov_Border'] * df_data_set['Log_TENB']\n",
    "\n",
    "df_data_set['Prov_Border X Cog_Dist'] = df_data_set['Prov_Border'] * df_data_set['Cog_Dist']\n",
    "\n",
    "df_data_set['Country_Border X Log_TENB'] = df_data_set['Country_Border'] * df_data_set['Log_TENB']\n",
    "\n",
    "df_data_set['Country_Border X Cog_Dist'] = df_data_set['Country_Border'] * df_data_set['Cog_Dist']\n",
    "\n",
    "\n",
    "\n",
    "columns = [  'Log_Geo_Dist',\n",
    "             'Log_TENB', \n",
    "             'Log_Geo_Dist X Log_TENB', \n",
    "             'Log_Geo_Dist_Sq', \n",
    "             'Log_Geo_Dist_Sq X Log_TENB',\n",
    "             'Log_Geo_Dist X Cog_Dist',\n",
    "             'Prov_Border X Log_TENB',\n",
    "             'Prov_Border X Cog_Dist',\n",
    "             'Country_Border X Log_TENB',\n",
    "             'Country_Border X Cog_Dist',\n",
    "             'TENB',\n",
    "             'Cog_Dist',\n",
    "             'Top_regions',\n",
    "             'Prov_Border',\n",
    "             'Country_Border',\n",
    "             'NotContig',\n",
    "             'Province_1_Alberta',\n",
    "             'Province_1_Arizona',\n",
    "             'Province_1_California',\n",
    "             'Province_1_Manitoba',\n",
    "             'Province_1_Quebec',\n",
    "             'Province_2_Alberta',\n",
    "             'Province_2_Arizona',\n",
    "             'Province_2_California',\n",
    "             'Province_2_Missouri',\n",
    "             'Province_2_Quebec',\n",
    "             'Province_1_Colorado',\n",
    "             'Province_1_Maryland',\n",
    "             'Province_1_Massachusetts',\n",
    "             'Province_1_Minnesota',\n",
    "             'Province_1_Missouri',\n",
    "             'Province_1_New York',\n",
    "             'Province_1_Ontario',\n",
    "             'Province_1_Pennsylvania',\n",
    "             'Province_1_Washington',\n",
    "             'Province_2_Colorado',\n",
    "             'Province_2_Maryland',\n",
    "             'Province_2_Massachusetts',\n",
    "             'Province_2_Minnesota',\n",
    "             'Province_2_New York',\n",
    "             'Province_2_Ontario',\n",
    "             'Province_2_Pennsylvania',\n",
    "             'Province_2_Washington',\n",
    "             'Province_1_Connecticut',\n",
    "             'Province_1_Florida',\n",
    "             'Province_1_Illinois',\n",
    "             'Province_1_Iowa',\n",
    "             'Province_1_Oklahoma',\n",
    "             'Province_1_South Carolina',\n",
    "             'Province_2_Connecticut',\n",
    "             'Province_2_Florida',\n",
    "             'Province_2_Illinois',\n",
    "             'Province_2_Iowa',\n",
    "             'Province_2_Oklahoma',\n",
    "             'Province_2_South Carolina',\n",
    "             'Province_1_Alabama',\n",
    "             'Province_1_Arkansas',\n",
    "             'Province_1_Ohio',\n",
    "             'Province_1_Oregon',\n",
    "             'Province_1_Wisconsin',\n",
    "             'Province_2_Alabama',\n",
    "             'Province_2_Arkansas',\n",
    "             'Province_2_Manitoba',\n",
    "             'Province_2_Ohio',\n",
    "             'Province_2_Oregon',\n",
    "             'Province_2_Wisconsin',\n",
    "             'Province_1_British Columbia',\n",
    "             'Province_1_Louisiana',\n",
    "             'Province_1_Mississippi',\n",
    "             'Province_1_New Jersey',\n",
    "             'Province_1_Texas',\n",
    "             'Province_1_Wyoming',\n",
    "             'Province_2_British Columbia',\n",
    "             'Province_2_Louisiana',\n",
    "             'Province_2_Mississippi',\n",
    "             'Province_2_New Jersey',\n",
    "             'Province_2_Texas',\n",
    "             'Province_2_Wyoming',\n",
    "             'Province_1_Delaware',\n",
    "             'Province_1_District of Columbia',\n",
    "             'Province_1_Michigan',\n",
    "             'Province_1_Saskatchewan',\n",
    "             'Province_1_Tennessee',\n",
    "             'Province_1_Virginia',\n",
    "             'Province_2_Delaware',\n",
    "             'Province_2_District of Columbia',\n",
    "             'Province_2_Michigan',\n",
    "             'Province_2_Saskatchewan',\n",
    "             'Province_2_Tennessee',\n",
    "             'Province_2_Virginia',\n",
    "             'Province_1_Georgia',\n",
    "             'Province_2_Georgia',\n",
    "             'Province_2_North Carolina',\n",
    "             'Province_1_Indiana',\n",
    "             'Province_1_Kansas',\n",
    "             'Province_1_North Carolina',\n",
    "             'Province_2_Indiana',\n",
    "             'Province_2_Kansas',\n",
    "             'Province_1_Alaska',\n",
    "             'Province_2_Alaska',\n",
    "             'Province_1_New Mexico',\n",
    "             'Province_2_New Mexico',\n",
    "             'Province_1_Hawaii',\n",
    "             'Province_1_Idaho',\n",
    "             'Province_2_Hawaii',\n",
    "             'Province_2_Idaho',\n",
    "             'Province_1_Utah',\n",
    "             'Province_1_West Virginia',\n",
    "             'Province_2_Utah',\n",
    "             'Province_2_West Virginia',\n",
    "             'Province_1_Maine',\n",
    "             'Province_1_Nova Scotia',\n",
    "             'Province_1_Rhode Island',\n",
    "             'Province_2_Maine',\n",
    "             'Province_2_Nova Scotia',\n",
    "             'Province_2_Rhode Island',\n",
    "             'Province_1_Montana',\n",
    "             'Province_1_Nebraska',\n",
    "             'Province_1_Nevada',\n",
    "             'Province_1_New Brunswick',\n",
    "             'Province_1_New Hampshire',\n",
    "             'Province_1_Vermont',\n",
    "             'Province_2_Montana',\n",
    "             'Province_2_Nebraska',\n",
    "             'Province_2_Nevada',\n",
    "             'Province_2_New Brunswick',\n",
    "             'Province_2_New Hampshire',\n",
    "             'Province_2_Vermont']\n",
    "\n",
    "columns_clf = [  'Log_Geo_Dist',\n",
    "                 'Log_TENB',\n",
    "                 'Cog_Dist',\n",
    "                 'Prov_Border',\n",
    "                 'Country_Border',\n",
    "                 'NotContig',\n",
    "                 'Top_regions']\n",
    "\n",
    "X_clf = df_data_set[columns_clf]\n",
    "y = df_data_set.collaboration_binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd9ceea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset {0: 251480, 1: 1595}\n",
      "Dataset Test {0: 37723, 1: 239}\n"
     ]
    }
   ],
   "source": [
    "unique, count = np.unique (y, return_counts = True)\n",
    "\n",
    "y_value_count = {k : v for (k,v) in zip(unique,count)}\n",
    "\n",
    "print ('Dataset', y_value_count)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clf, y, test_size = 0.15, random_state = 123, stratify = y)\n",
    "\n",
    "unique, count = np.unique (y_test, return_counts = True)\n",
    "\n",
    "y_value_count = {k : v for (k,v) in zip(unique,count)}\n",
    "\n",
    "print ('Dataset Test', y_value_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "blond-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(max_iter = 500)\n",
    "rnd = RandomForestClassifier(random_state = 123, n_jobs = -1)\n",
    "gbc = GradientBoostingClassifier(random_state = 123)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric = 'logloss', random_state = 123, n_jobs = -1)\n",
    "knn = KNeighborsClassifier(n_jobs = -1)\n",
    "rus = RandomUnderSampler()\n",
    "ros = RandomOverSampler()\n",
    "smt = SMOTENC(categorical_features = [3,4,5,6], random_state = 123, n_jobs = -1)\n",
    "smtk = SMOTETomek(n_jobs = 6)\n",
    "smnn = SMOTEENN(n_jobs = 6)\n",
    "scl = StandardScaler()\n",
    "feature_selection_selbest = SelectKBest(chi2, k=7)\n",
    "feature_selection_selmodel = SelectFromModel(rnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64e0e3e5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result for LogisticRegression(max_iter=500) is:\n",
      "F1_Score: 0.7589498806682577\n",
      "Presicion: 0.8833333333333333\n",
      "Recall: 0.6652719665271967\n",
      "Accuracy: 0.9973394447078657\n",
      "roc_auc_score: 0.8323576384872019\n",
      "confusion_matrix:\n",
      "[[37702    21]\n",
      " [   80   159]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37723\n",
      "           1       0.88      0.67      0.76       239\n",
      "\n",
      "    accuracy                           1.00     37962\n",
      "   macro avg       0.94      0.83      0.88     37962\n",
      "weighted avg       1.00      1.00      1.00     37962\n",
      "\n",
      "\n",
      "\n",
      "The result for RandomForestClassifier(n_jobs=-1, random_state=123) is:\n",
      "F1_Score: 0.8836206896551724\n",
      "Presicion: 0.9111111111111111\n",
      "Recall: 0.8577405857740585\n",
      "Accuracy: 0.9985775248933144\n",
      "roc_auc_score: 0.9286052026237946\n",
      "confusion_matrix:\n",
      "[[37703    20]\n",
      " [   34   205]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37723\n",
      "           1       0.91      0.86      0.88       239\n",
      "\n",
      "    accuracy                           1.00     37962\n",
      "   macro avg       0.96      0.93      0.94     37962\n",
      "weighted avg       1.00      1.00      1.00     37962\n",
      "\n",
      "\n",
      "\n",
      "The result for GradientBoostingClassifier(random_state=123) is:\n",
      "F1_Score: 0.8\n",
      "Presicion: 0.8640776699029126\n",
      "Recall: 0.7447698744769874\n",
      "Accuracy: 0.9976555502871293\n",
      "roc_auc_score: 0.8720138108699652\n",
      "confusion_matrix:\n",
      "[[37695    28]\n",
      " [   61   178]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37723\n",
      "           1       0.86      0.74      0.80       239\n",
      "\n",
      "    accuracy                           1.00     37962\n",
      "   macro avg       0.93      0.87      0.90     37962\n",
      "weighted avg       1.00      1.00      1.00     37962\n",
      "\n",
      "\n",
      "\n",
      "The result for XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
      "              colsample_bynode=None, colsample_bytree=None,\n",
      "              eval_metric='logloss', gamma=None, gpu_id=None,\n",
      "              importance_type='gain', interaction_constraints=None,\n",
      "              learning_rate=None, max_delta_step=None, max_depth=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
      "              random_state=123, reg_alpha=None, reg_lambda=None,\n",
      "              scale_pos_weight=None, subsample=None, tree_method=None,\n",
      "              use_label_encoder=False, validate_parameters=None,\n",
      "              verbosity=None) is:\n",
      "F1_Score: 0.8675213675213675\n",
      "Presicion: 0.8864628820960698\n",
      "Recall: 0.8493723849372385\n",
      "Accuracy: 0.9983667878404721\n",
      "roc_auc_score: 0.9243415751264142\n",
      "confusion_matrix:\n",
      "[[37697    26]\n",
      " [   36   203]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37723\n",
      "           1       0.89      0.85      0.87       239\n",
      "\n",
      "    accuracy                           1.00     37962\n",
      "   macro avg       0.94      0.92      0.93     37962\n",
      "weighted avg       1.00      1.00      1.00     37962\n",
      "\n",
      "\n",
      "\n",
      "The result for KNeighborsClassifier(n_jobs=-1) is:\n",
      "F1_Score: 0.8260869565217391\n",
      "Presicion: 0.8597285067873304\n",
      "Recall: 0.7949790794979079\n",
      "Accuracy: 0.9978926294715769\n",
      "roc_auc_score: 0.8970786498409402\n",
      "confusion_matrix:\n",
      "[[37692    31]\n",
      " [   49   190]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37723\n",
      "           1       0.86      0.79      0.83       239\n",
      "\n",
      "    accuracy                           1.00     37962\n",
      "   macro avg       0.93      0.90      0.91     37962\n",
      "weighted avg       1.00      1.00      1.00     37962\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# baseline selection\n",
    "\n",
    "clfs = [logreg, rnd, gbc, xgb, knn]\n",
    "\n",
    "for clf in clfs:\n",
    "    \n",
    "    print (f'The result for {clf} is:')\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print ('F1_Score:', f1_score(y_test, y_pred))\n",
    "    print ('Presicion:' , precision_score(y_test, y_pred))\n",
    "    print ('Recall:' , recall_score(y_test, y_pred))\n",
    "    print ('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print ('roc_auc_score:', roc_auc_score(y_test, y_pred))\n",
    "    print ('confusion_matrix:')\n",
    "    print (confusion_matrix(y_test, y_pred))\n",
    "    print ('Classification Report:')\n",
    "    print (classification_report(y_test, y_pred))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2506d2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result for RandomForestClassifier(n_jobs=-1, random_state=123) is:\n",
      "F1_Score: 0.8836206896551724\n",
      "Presicion: 0.9111111111111111\n",
      "Recall: 0.8577405857740585\n",
      "Accuracy: 0.9985775248933144\n",
      "roc_auc_score: 0.9286052026237946\n",
      "confusion_matrix:\n",
      "[[37703    20]\n",
      " [   34   205]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37723\n",
      "           1       0.91      0.86      0.88       239\n",
      "\n",
      "    accuracy                           1.00     37962\n",
      "   macro avg       0.96      0.93      0.94     37962\n",
      "weighted avg       1.00      1.00      1.00     37962\n",
      "\n",
      "\n",
      "\n",
      "The result for Pipeline(steps=[['feature_selection',\n",
      "                 SelectFromModel(estimator=RandomForestClassifier(n_jobs=-1,\n",
      "                                                                  random_state=123))],\n",
      "                ['RandomForestClassifier',\n",
      "                 RandomForestClassifier(n_jobs=-1, random_state=123)]]) is:\n",
      "F1_Score: 0.8787878787878788\n",
      "Presicion: 0.9103139013452914\n",
      "Recall: 0.8493723849372385\n",
      "Accuracy: 0.9985248406301038\n",
      "roc_auc_score: 0.9244211022053846\n",
      "confusion_matrix:\n",
      "[[37703    20]\n",
      " [   36   203]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37723\n",
      "           1       0.91      0.85      0.88       239\n",
      "\n",
      "    accuracy                           1.00     37962\n",
      "   macro avg       0.95      0.92      0.94     37962\n",
      "weighted avg       1.00      1.00      1.00     37962\n",
      "\n",
      "\n",
      "\n",
      "The result for Pipeline(steps=[['SCL', StandardScaler()],\n",
      "                ['RandomForestClassifier',\n",
      "                 RandomForestClassifier(n_jobs=-1, random_state=123)]]) is:\n",
      "F1_Score: 0.886021505376344\n",
      "Presicion: 0.911504424778761\n",
      "Recall: 0.8619246861924686\n",
      "Accuracy: 0.9986038670249197\n",
      "roc_auc_score: 0.9306972528329998\n",
      "confusion_matrix:\n",
      "[[37703    20]\n",
      " [   33   206]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37723\n",
      "           1       0.91      0.86      0.89       239\n",
      "\n",
      "    accuracy                           1.00     37962\n",
      "   macro avg       0.96      0.93      0.94     37962\n",
      "weighted avg       1.00      1.00      1.00     37962\n",
      "\n",
      "\n",
      "\n",
      "The result for Pipeline(steps=[['SMOTENC',\n",
      "                 SMOTENC(categorical_features=[3, 4, 5, 6], random_state=123)],\n",
      "                ['RandomForestClassifier',\n",
      "                 RandomForestClassifier(n_jobs=-1, random_state=123)]]) is:\n",
      "F1_Score: 0.6264044943820225\n",
      "Presicion: 0.4714587737843552\n",
      "Recall: 0.9330543933054394\n",
      "Accuracy: 0.992992992992993\n",
      "roc_auc_score: 0.9632135683622868\n",
      "confusion_matrix:\n",
      "[[37473   250]\n",
      " [   16   223]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     37723\n",
      "           1       0.47      0.93      0.63       239\n",
      "\n",
      "    accuracy                           0.99     37962\n",
      "   macro avg       0.74      0.96      0.81     37962\n",
      "weighted avg       1.00      0.99      0.99     37962\n",
      "\n",
      "\n",
      "\n",
      "The result for Pipeline(steps=[['RandomOverSampler', RandomOverSampler()],\n",
      "                ['RandomForestClassifier',\n",
      "                 RandomForestClassifier(n_jobs=-1, random_state=123)]]) is:\n",
      "F1_Score: 0.8837209302325582\n",
      "Presicion: 0.8931623931623932\n",
      "Recall: 0.8744769874476988\n",
      "Accuracy: 0.9985511827617091\n",
      "roc_auc_score: 0.936907130894806\n",
      "confusion_matrix:\n",
      "[[37698    25]\n",
      " [   30   209]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37723\n",
      "           1       0.89      0.87      0.88       239\n",
      "\n",
      "    accuracy                           1.00     37962\n",
      "   macro avg       0.95      0.94      0.94     37962\n",
      "weighted avg       1.00      1.00      1.00     37962\n",
      "\n",
      "\n",
      "\n",
      "The result for Pipeline(steps=[['RandomUnderSampler', RandomUnderSampler()],\n",
      "                ['RandomForestClassifier',\n",
      "                 RandomForestClassifier(n_jobs=-1, random_state=123)]]) is:\n",
      "F1_Score: 0.3384841795437822\n",
      "Presicion: 0.20535714285714285\n",
      "Recall: 0.9623430962343096\n",
      "Accuracy: 0.9763184236868447\n",
      "roc_auc_score: 0.9693750314032137\n",
      "confusion_matrix:\n",
      "[[36833   890]\n",
      " [    9   230]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     37723\n",
      "           1       0.21      0.96      0.34       239\n",
      "\n",
      "    accuracy                           0.98     37962\n",
      "   macro avg       0.60      0.97      0.66     37962\n",
      "weighted avg       0.99      0.98      0.98     37962\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# baseline (RandomForest)\n",
    "\n",
    "pipe_fs = Pipeline(steps = [['feature_selection', feature_selection_selmodel], ['RandomForestClassifier', rnd]])\n",
    "pipe_scl = Pipeline(steps = [['SCL', scl], ['RandomForestClassifier', rnd]])\n",
    "pipe_smt = Imbpipeline(steps = [['SMOTENC', smt], ['RandomForestClassifier', rnd]])\n",
    "pipe_ros = Imbpipeline(steps = [['RandomOverSampler', ros], ['RandomForestClassifier', rnd]])\n",
    "pipe_rus = Imbpipeline(steps = [['RandomUnderSampler', rus], ['RandomForestClassifier', rnd]])\n",
    "\n",
    "\n",
    "clfs = [rnd, pipe_fs, pipe_scl, pipe_smt, pipe_ros, pipe_rus]\n",
    "\n",
    "for clf in clfs:\n",
    "    \n",
    "    print (f'The result for {clf} is:')\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print ('F1_Score:', f1_score(y_test, y_pred))\n",
    "    print ('Presicion:' , precision_score(y_test, y_pred))\n",
    "    print ('Recall:' , recall_score(y_test, y_pred))\n",
    "    print ('Accuracy:', accuracy_score(y_test, y_pred))\n",
    "    print ('roc_auc_score:', roc_auc_score(y_test, y_pred))\n",
    "    print ('confusion_matrix:')\n",
    "    print (confusion_matrix(y_test, y_pred))\n",
    "    print ('Classification Report:')\n",
    "    print (classification_report(y_test, y_pred))\n",
    "    print('\\n')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f57490d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning - Randomforestclassifier - RandomSearch\n",
    "\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 50, stop = 300, num = 26)]\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "max_features = ['auto', 'sqrt', .1, .2, .3, .4, .5]\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(40, 60, num = 20)]\n",
    "max_depth.append(None)\n",
    "\n",
    "min_samples_split = [2,3,4,5,6,7,8,9]\n",
    "\n",
    "min_samples_leaf = [1,2]\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_dist = { 'n_estimators': n_estimators,\n",
    "               'criterion': criterion,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# print('Parameters used in the grid:\\n')\n",
    "# pprint(param_dist)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "rnd_srch_model = RandomizedSearchCV(estimator = rnd,\n",
    "                           param_distributions = param_dist, \n",
    "                           cv = skf, n_jobs = -1, \n",
    "                           verbose = 1,\n",
    "                           n_iter = 200,\n",
    "                           scoring = 'f1',\n",
    "                           random_state = 123)\n",
    "\n",
    "rnd_srch_model.fit(X_train, y_train)\n",
    "# y_pred = rnd_srch_model.best_estimator_.predict(X_test)\n",
    "print ('Best Parameters', rnd_srch_model.best_params_)\n",
    "print ('Best Score', rnd_srch_model.best_score_)\n",
    "\n",
    "# print ('Presicion:' , precision_score(y_test, y_pred))\n",
    "# print ('Recall:' , recall_score(y_test, y_pred))\n",
    "# print ('F1_Score:', f1_score(y_test, y_pred))\n",
    "\n",
    "\n",
    "# Best Parameters {'n_estimators': 170, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 55, 'criterion': 'gini', 'bootstrap': True}\n",
    "# Best Score 0.8852592313348533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f36af29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.8808510638297872\n",
      "Presicion: 0.8961038961038961\n",
      "Recall: 0.8661087866108786\n",
      "Accuracy: 0.9985248406301038\n",
      "confusion_matrix:\n",
      "[[37699    24]\n",
      " [   32   207]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37723\n",
      "           1       0.90      0.87      0.88       239\n",
      "\n",
      "    accuracy                           1.00     37962\n",
      "   macro avg       0.95      0.93      0.94     37962\n",
      "weighted avg       1.00      1.00      1.00     37962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Search Best parameters result (test data)\n",
    "\n",
    "rnd_best = RandomForestClassifier(random_state = 123, n_jobs = -1,\n",
    "                                       n_estimators = 170,\n",
    "                                       min_samples_split = 5,\n",
    "                                       min_samples_leaf = 1,\n",
    "                                       max_features = 'sqrt',\n",
    "                                       criterion = 'gini',\n",
    "                                       max_depth = 55,\n",
    "                                       bootstrap = True)\n",
    "\n",
    "rnd_best.fit(X_train, y_train)\n",
    "y_pred_best = rnd_best.predict(X_test)\n",
    "print ('F1_Score:', f1_score(y_test, y_pred_best))\n",
    "print ('Presicion:' , precision_score(y_test, y_pred_best))\n",
    "print ('Recall:' , recall_score(y_test, y_pred_best))\n",
    "print ('Accuracy:', accuracy_score(y_test, y_pred_best))\n",
    "print ('confusion_matrix:')\n",
    "print (confusion_matrix(y_test, y_pred_best))\n",
    "print ('Classification Report:')\n",
    "print (classification_report(y_test, y_pred_best))\n",
    "\n",
    "# rfc_cv_score = cross_val_score(rnd_best, X_train, y_train, cv = skf, scoring = 'f1')\n",
    "\n",
    "# print ('F1_Score_cv_score:', rfc_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69bdce99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters used in the grid:\n",
      "\n",
      "{'bootstrap': [True, False],\n",
      " 'criterion': ['gini', 'entropy'],\n",
      " 'max_depth': [53, 54, 55, 56, 57, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1],\n",
      " 'min_samples_split': [4, 5, 6],\n",
      " 'n_estimators': [160, 170, 180]}\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Best Parameters {'bootstrap': True, 'criterion': 'gini', 'max_depth': 53, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 170}\n",
      "Best Score 0.8852592313348533\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter tuning - Randomforestclassifier - Grid search\n",
    "\n",
    "\n",
    "n_estimators = [int(x) for x in np.linspace(start = 160, stop = 180, num = 3)]\n",
    "\n",
    "max_features = ['auto','sqrt']\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(53, 57, num = 5)]\n",
    "max_depth.append(None)\n",
    "\n",
    "min_samples_split = [4,5,6]\n",
    "\n",
    "min_samples_leaf = [1]\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "\n",
    "param_grid = { 'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap,\n",
    "               'criterion' : criterion}\n",
    "\n",
    "print('Parameters used in the grid:\\n')\n",
    "pprint(param_grid)\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5)\n",
    "\n",
    "grid_model = GridSearchCV(estimator = rnd,\n",
    "                         param_grid = param_grid, \n",
    "                         cv = skf, n_jobs = -1, \n",
    "                         verbose = 1,\n",
    "                         scoring = 'f1')\n",
    "\n",
    "grid_model.fit(X_train, y_train)\n",
    "\n",
    "print ('Best Parameters', grid_model.best_params_)\n",
    "print ('Best Score', grid_model.best_score_)\n",
    "\n",
    "\n",
    "# Best Parameters {'bootstrap': True, 'criterion': 'gini', 'max_depth': 53, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 170}\n",
    "# Best Score 0.8852592313348533"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4177b5da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1_Score: 0.8808510638297872\n",
      "Presicion: 0.8961038961038961\n",
      "Recall: 0.8661087866108786\n",
      "Accuracy: 0.9985248406301038\n",
      "roc_auc_score: 0.9327362849895577\n",
      "confusion_matrix:\n",
      "[[37699    24]\n",
      " [   32   207]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37723\n",
      "           1       0.90      0.87      0.88       239\n",
      "\n",
      "    accuracy                           1.00     37962\n",
      "   macro avg       0.95      0.93      0.94     37962\n",
      "weighted avg       1.00      1.00      1.00     37962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# grid Search Best parameters result (test data)\n",
    "\n",
    "grd_best = RandomForestClassifier(random_state = 123, n_jobs = -1,\n",
    "                                       criterion = 'gini',\n",
    "                                       n_estimators = 170,\n",
    "                                       min_samples_split = 5,\n",
    "                                       min_samples_leaf = 1,\n",
    "                                       max_features = 'auto',\n",
    "                                       max_depth = 53,\n",
    "                                       bootstrap = True)\n",
    "\n",
    "grd_best.fit(X_train, y_train)\n",
    "y_pred_best_grd = grd_best.predict(X_test)\n",
    "print ('F1_Score:', f1_score(y_test, y_pred_best_grd))\n",
    "print ('Presicion:' , precision_score(y_test, y_pred_best_grd))\n",
    "print ('Recall:' , recall_score(y_test, y_pred_best_grd))\n",
    "print ('Accuracy:', accuracy_score(y_test, y_pred_best_grd))\n",
    "print ('roc_auc_score:', roc_auc_score(y_test, y_pred_best_grd))\n",
    "print ('confusion_matrix:')\n",
    "print (confusion_matrix(y_test, y_pred_best_grd))\n",
    "print ('Classification Report:')\n",
    "print (classification_report(y_test, y_pred_best_grd))\n",
    "\n",
    "# rfc_cv_score = cross_val_score(rnd_best, X_train, y_train, cv = skf, scoring = 'f1')\n",
    "\n",
    "# print ('F1_Score_cv_score:', rfc_cv_score.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b873788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Feature', ylabel='mean decrease in impurity (%)'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Feature importance - mean decrease in impurity\n",
    "\n",
    "importances = grd_best.feature_importances_ * 100\n",
    "\n",
    "\n",
    "df_importance = pd.DataFrame()\n",
    "\n",
    "df_importance.insert(0,'Feature','')\n",
    "df_importance.insert(1,'importance',0)\n",
    "\n",
    "j = 0\n",
    "for i in columns_clf:\n",
    "    df_importance.loc[j,'Feature'] = i\n",
    "    df_importance.loc[j,'importance'] = importances[j]\n",
    "    j += 1\n",
    "\n",
    "df_importance.sort_values(by=['importance'], ascending=False, inplace = True)\n",
    "\n",
    "df_importance[:10].plot(x = 'Feature', y = 'importance', kind = 'bar', rot = 90, ylabel = 'mean decrease in impurity (%)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "62a3988d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.010506\n",
      "         Iterations 13\n",
      "                             Results: Logit\n",
      "========================================================================\n",
      "Model:                Logit                 Pseudo R-squared:  0.725    \n",
      "Dependent Variable:   collaboration_binary  AIC:               5331.8292\n",
      "Date:                 2021-08-31 11:36      BIC:               5404.9193\n",
      "No. Observations:     253075                Log-Likelihood:    -2658.9  \n",
      "Df Model:             6                     LL-Null:           -9671.5  \n",
      "Df Residuals:         253068                LLR p-value:       0.0000   \n",
      "Converged:            1.0000                Scale:             1.0000   \n",
      "No. Iterations:       13.0000                                           \n",
      "------------------------------------------------------------------------\n",
      "                         Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "------------------------------------------------------------------------\n",
      "Log_Geo_Dist            -0.4494   0.0311 -14.4411 0.0000 -0.5104 -0.3884\n",
      "Log_TENB                 3.8091   0.1158  32.9065 0.0000  3.5823  4.0360\n",
      "Log_Geo_Dist X Cog_Dist -0.3182   0.0554  -5.7469 0.0000 -0.4267 -0.2097\n",
      "Cog_Dist                -3.5754   0.2475 -14.4433 0.0000 -4.0606 -3.0902\n",
      "Prov_Border             -0.5134   0.1780  -2.8834 0.0039 -0.8623 -0.1644\n",
      "Country_Border          -0.7383   0.2143  -3.4448 0.0006 -1.1583 -0.3182\n",
      "NotContig               -0.1470   0.0975  -1.5082 0.1315 -0.3380  0.0440\n",
      "========================================================================\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.010518\n",
      "         Iterations 13\n",
      "                            Results: Logit\n",
      "=======================================================================\n",
      "Model:               Logit                 Pseudo R-squared:  0.725    \n",
      "Dependent Variable:  collaboration_binary  AIC:               5337.4502\n",
      "Date:                2021-08-31 11:36      BIC:               5410.5403\n",
      "No. Observations:    253075                Log-Likelihood:    -2661.7  \n",
      "Df Model:            6                     LL-Null:           -9671.5  \n",
      "Df Residuals:        253068                LLR p-value:       0.0000   \n",
      "Converged:           1.0000                Scale:             1.0000   \n",
      "No. Iterations:      13.0000                                           \n",
      "-----------------------------------------------------------------------\n",
      "                        Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "-----------------------------------------------------------------------\n",
      "Log_Geo_Dist           -0.5302   0.0289 -18.3580 0.0000 -0.5868 -0.4736\n",
      "Log_TENB                3.8255   0.1159  33.0050 0.0000  3.5984  4.0527\n",
      "Cog_Dist               -3.9861   0.2135 -18.6741 0.0000 -4.4045 -3.5677\n",
      "Prov_Border            -0.0265   0.1986  -0.1337 0.8937 -0.4157  0.3626\n",
      "Prov_Border X Cog_Dist -1.8096   0.3510  -5.1549 0.0000 -2.4976 -1.1215\n",
      "Country_Border         -0.7254   0.2145  -3.3817 0.0007 -1.1458 -0.3050\n",
      "NotContig              -0.0670   0.0935  -0.7165 0.4737 -0.2502  0.1162\n",
      "=======================================================================\n",
      "\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.010565\n",
      "         Iterations 14\n",
      "                              Results: Logit\n",
      "==========================================================================\n",
      "Model:                Logit                  Pseudo R-squared:   0.724    \n",
      "Dependent Variable:   collaboration_binary   AIC:                5361.4890\n",
      "Date:                 2021-08-31 11:36       BIC:                5434.5790\n",
      "No. Observations:     253075                 Log-Likelihood:     -2673.7  \n",
      "Df Model:             6                      LL-Null:            -9671.5  \n",
      "Df Residuals:         253068                 LLR p-value:        0.0000   \n",
      "Converged:            1.0000                 Scale:              1.0000   \n",
      "No. Iterations:       14.0000                                             \n",
      "--------------------------------------------------------------------------\n",
      "                           Coef.  Std.Err.    z     P>|z|   [0.025  0.975]\n",
      "--------------------------------------------------------------------------\n",
      "Log_Geo_Dist              -0.5162   0.0291 -17.7295 0.0000 -0.5732 -0.4591\n",
      "Log_TENB                   3.8878   0.1164  33.3942 0.0000  3.6596  4.1160\n",
      "Cog_Dist                  -4.7538   0.1747 -27.2093 0.0000 -5.0962 -4.4113\n",
      "Prov_Border               -0.5062   0.1775  -2.8520 0.0043 -0.8541 -0.1583\n",
      "Country_Border            -0.2827   0.3167  -0.8925 0.3721 -0.9034  0.3381\n",
      "Country_Border X Cog_Dist -2.1509   1.3088  -1.6434 0.1003 -4.7160  0.4143\n",
      "NotContig                  0.0894   0.0897   0.9972 0.3187 -0.0863  0.2652\n",
      "==========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Logit regression\n",
    "\n",
    "\n",
    "columns_reg0 = [ 'Log_Geo_Dist',\n",
    "                 'Prov_Border',\n",
    "                 'Country_Border',\n",
    "                 'NotContig',\n",
    "                 'Top_regions']\n",
    "\n",
    "columns_reg1 = [ 'Log_Geo_Dist',\n",
    "                 'Log_TENB',\n",
    "                 'Cog_Dist',\n",
    "                 'Prov_Border',\n",
    "                 'Country_Border',\n",
    "                 'NotContig',\n",
    "                 'Top_regions']\n",
    "\n",
    "columns_reg2 = [ 'Log_Geo_Dist',\n",
    "                 'Log_TENB',\n",
    "                 'Log_Geo_Dist X Log_TENB', \n",
    "                 'Cog_Dist',\n",
    "                 'Prov_Border',\n",
    "                 'Country_Border',\n",
    "                 'NotContig',\n",
    "                 'Top_regions']\n",
    "\n",
    "\n",
    "#              'Prov_Border X Cog_Dist',\n",
    "#              'Country_Border X Log_TENB',\n",
    "#              'Country_Border X Cog_Dist',\n",
    "\n",
    "columns_reg21 = ['Log_Geo_Dist',\n",
    "                 'Log_TENB',\n",
    "                 'Prov_Border X Log_TENB',\n",
    "                 'Cog_Dist',\n",
    "                 'Prov_Border',\n",
    "                 'Country_Border',\n",
    "                 'NotContig',\n",
    "                 'Top_regions']\n",
    "\n",
    "columns_reg22 = ['Log_Geo_Dist',\n",
    "                 'Log_TENB',\n",
    "                 'Country_Border X Log_TENB',\n",
    "                 'Cog_Dist',\n",
    "                 'Prov_Border',\n",
    "                 'Country_Border',\n",
    "                 'NotContig',\n",
    "                 'Top_regions']\n",
    "\n",
    "columns_reg3 = [ 'Log_Geo_Dist',\n",
    "                 'Log_TENB',\n",
    "                 'Log_Geo_Dist X Cog_Dist',\n",
    "                 'Cog_Dist',\n",
    "                 'Prov_Border',\n",
    "                 'Country_Border',\n",
    "                 'NotContig']\n",
    "\n",
    "columns_reg4 = [ 'Log_Geo_Dist',\n",
    "                 'Log_TENB',\n",
    "                 'Cog_Dist',\n",
    "                 'Prov_Border',\n",
    "                 'Prov_Border X Log_TENB',\n",
    "                 'Country_Border',\n",
    "                 'NotContig']\n",
    "\n",
    "columns_reg5 = [ 'Log_Geo_Dist',\n",
    "                 'Log_TENB',\n",
    "                 'Cog_Dist',\n",
    "                 'Prov_Border',\n",
    "                 'Prov_Border X Cog_Dist',\n",
    "                 'Country_Border',\n",
    "                 'NotContig']\n",
    "\n",
    "columns_reg6 = [ 'Log_Geo_Dist',\n",
    "                 'Log_TENB',\n",
    "                 'Cog_Dist',\n",
    "                 'Prov_Border',\n",
    "                 'Country_Border',\n",
    "                 'Country_Border X Log_TENB',\n",
    "                 'NotContig']\n",
    "\n",
    "columns_reg7 = [ 'Log_Geo_Dist',\n",
    "                 'Log_TENB',\n",
    "                 'Cog_Dist',\n",
    "                 'Prov_Border',\n",
    "                 'Country_Border',\n",
    "                 'Country_Border X Cog_Dist',\n",
    "                 'NotContig']\n",
    "\n",
    "X_reg0 = df_data_set[columns_reg0]\n",
    "X_reg1 = df_data_set[columns_reg1]\n",
    "X_reg2 = df_data_set[columns_reg2]\n",
    "X_reg21 = df_data_set[columns_reg21]\n",
    "X_reg22 = df_data_set[columns_reg22]\n",
    "X_reg3 = df_data_set[columns_reg3]\n",
    "X_reg4 = df_data_set[columns_reg4]\n",
    "X_reg5 = df_data_set[columns_reg5]\n",
    "X_reg6 = df_data_set[columns_reg6]\n",
    "X_reg7 = df_data_set[columns_reg7]\n",
    "\n",
    "X_reg_0 = sm.tools.tools.add_constant(X_reg0, prepend=True, has_constant='add')\n",
    "X_reg_1 = sm.tools.tools.add_constant(X_reg1, prepend=True, has_constant='add')\n",
    "X_reg_2 = sm.tools.tools.add_constant(X_reg2, prepend=True, has_constant='add')\n",
    "X_reg_3 = sm.tools.tools.add_constant(X_reg3, prepend=True, has_constant='add')\n",
    "X_reg_4 = sm.tools.tools.add_constant(X_reg4, prepend=True, has_constant='add')\n",
    "X_reg_5 = sm.tools.tools.add_constant(X_reg5, prepend=True, has_constant='add')\n",
    "X_reg_6 = sm.tools.tools.add_constant(X_reg6, prepend=True, has_constant='add')\n",
    "X_reg_7 = sm.tools.tools.add_constant(X_reg7, prepend=True, has_constant='add')\n",
    "\n",
    "\n",
    "xx = [X_reg3, X_reg5, X_reg7]\n",
    "\n",
    "for xx in xx:\n",
    "    logit_model=sm.Logit(y, xx)\n",
    "    result=logit_model.fit(method_kwargs={\"warn_convergence\": False})\n",
    "    print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6566bba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve - n_estimators\n",
    "\n",
    "param_range = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "train_scores, test_scores = validation_curve(rnd, X_train, y_train, \n",
    "                           param_name = 'n_estimators', \n",
    "                           param_range = param_range,\n",
    "                           cv = skf, n_jobs = -1, verbose = 30, scoring = 'f1')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with RandomForest\")\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(.85, 1.05)\n",
    "\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "test_scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7567d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve - max_depth\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(0, 150, num = 30)]\n",
    "max_depth.append(None)\n",
    "\n",
    "param_range = max_depth\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "train_scores, test_scores = validation_curve(rnd, X_train, y_train, \n",
    "                           param_name = 'max_depth', \n",
    "                           param_range = param_range,\n",
    "                           cv = skf, n_jobs = -1, verbose = 45, scoring = 'f1')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with RandomForest\")\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(.8, 1)\n",
    "\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "# plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "#                  train_scores_mean + train_scores_std, alpha=0.2,\n",
    "#                  color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "# plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "#                  test_scores_mean + test_scores_std, alpha=0.2,\n",
    "#                  color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "test_scores_mean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc9ee84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve - min_sample_split\n",
    "\n",
    "min_sample_split = [1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "param_range = min_sample_split\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "train_scores, test_scores = validation_curve(rnd, X_train, y_train, \n",
    "                           param_name = 'min_samples_split', \n",
    "                           param_range = param_range,\n",
    "                           cv = skf, n_jobs = -1, verbose = 30, scoring = 'f1')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with RandomForest\")\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(.8, 1)\n",
    "\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0c64f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve - min_sample_leaf\n",
    "\n",
    "min_sample_leaf = [0,1,2,3,4,5,6,7,8,9,10]\n",
    "\n",
    "param_range = min_sample_leaf\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "train_scores, test_scores = validation_curve(rnd, X_train, y_train, \n",
    "                           param_name = 'min_samples_leaf', \n",
    "                           param_range = param_range,\n",
    "                           cv = skf, n_jobs = -1, verbose = 50, scoring = 'f1')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with RandomForest\")\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(.8, 1)\n",
    "\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e21cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve - bootstrap\n",
    "\n",
    "bootstrap = [True, False]\n",
    "\n",
    "param_range = bootstrap\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "train_scores, test_scores = validation_curve(rnd, X_train, y_train, \n",
    "                           param_name = 'bootstrap', \n",
    "                           param_range = param_range,\n",
    "                           cv = skf, n_jobs = -1, verbose = 6, scoring = 'f1')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with RandomForest\")\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(.8, 1)\n",
    "\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb60f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve - criterion\n",
    "\n",
    "criterion = ['gini', 'entropy']\n",
    "\n",
    "param_range = criterion\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "train_scores, test_scores = validation_curve(rnd, X_train, y_train, \n",
    "                           param_name = 'criterion', \n",
    "                           param_range = param_range,\n",
    "                           cv = skf, n_jobs = -1, verbose = 6, scoring = 'f1')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with RandomForest\")\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(.8, 1)\n",
    "\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f477825",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve - max_features\n",
    "\n",
    "max_features = ['auto', 'sqrt', .1, .2, .3, .4, .5, .6, .7, .8, .9]\n",
    "\n",
    "param_range = max_features\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 3)\n",
    "\n",
    "train_scores, test_scores = validation_curve(rnd, X_train, y_train, \n",
    "                           param_name = 'max_features', \n",
    "                           param_range = param_range,\n",
    "                           cv = skf, n_jobs = -1, verbose = 6, scoring = 'f1')\n",
    "\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "train_scores_std = np.std(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "test_scores_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.title(\"Validation Curve with RandomForest\")\n",
    "plt.xlabel(r\"$\\gamma$\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(.8, 1)\n",
    "\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "test_scores_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f7be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature selection\n",
    "\n",
    "print ('Original data size: ', X.shape)\n",
    "\n",
    "var = VarianceThreshold(threshold=(.9 * (1 - .9)))\n",
    "var_fit = var.fit_transform(X)\n",
    "\n",
    "print ('Low variance removal: ', var_fit.shape)\n",
    "\n",
    "feature_idx = var.get_support()\n",
    "my_features_var = X.columns[feature_idx].tolist()\n",
    "print ('Variance threshold list of features:', my_features_var)\n",
    "\n",
    "selbest = SelectKBest(chi2, k=40)\n",
    "selbest_fit = selbest.fit_transform(X, y)\n",
    "print ('SelectKBest: ', selbest_fit.shape)\n",
    "feature_idx = selbest.get_support()\n",
    "my_features_selbest = X.columns[feature_idx].tolist()\n",
    "print ('SelectKBest list of features:', my_features_selbest)\n",
    "\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "\n",
    "selmodel = SelectFromModel(logreg).fit(X, y)\n",
    "X_new = selmodel.transform(X)\n",
    "print ('SelectFromModel', X_new.shape)\n",
    "\n",
    "feature_idx = selmodel.get_support()\n",
    "my_features_selmodel = X.columns[feature_idx].tolist()\n",
    "print ('SelectKBest list of features:', my_features_selmodel)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
