{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlarging the screen\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML(data=\"\"\"\n",
    "<style>\n",
    "    div#notebook-container    { width: 95%; }\n",
    "    div#menubar-container     { width: 85%; }\n",
    "    div#maintoolbar-container { width: 99%; }\n",
    "</style>\n",
    "\"\"\"))\n",
    "\n",
    "print ('Enlarging the screen is done!')\n",
    "\n",
    "# Importing libraries\n",
    "\n",
    "import numpy\n",
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option('max_colwidth', 100)\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n",
    "\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "print ('Libraries were imported successfully!')\n",
    "\n",
    "# Loading data from sql\n",
    "\n",
    "Server = 'LAPTOP-I7NEB9V3\\SQLEXPRESS'\n",
    "Database = 'Geopattern'\n",
    "Driver = 'ODBC Driver 17 for SQL Server'\n",
    "Database_Connection = f'mssql://@{Server}/{Database}?driver={Driver}'\n",
    "\n",
    "engine = create_engine(Database_Connection)\n",
    "connection = engine.connect()\n",
    "\n",
    "df_my_data = pd.read_sql_query (\n",
    "    \"select * from my_data\", connection)\n",
    "\n",
    "df_Authors = pd.read_sql_query (\n",
    "    \"select * from my_data_Authors\", connection)\n",
    "\n",
    "df_Authors['Country'].replace({'Czechia': 'Czech Republic', \n",
    "                               \"CÃ´te d'Ivoire\":\"Cote d'Ivoire\",\n",
    "                               'Democratic Republic of the Congo':'Democratic Republic Congo',\n",
    "                               'Myanmar (Burma)':'Myanmar',\n",
    "                               'North Macedonia':'Macedonia',\n",
    "                               'Republic of the Congo':'Brazzaville',\n",
    "                               'The Bahamas':'Bahamas',\n",
    "                               'Timor-Leste': 'Timor Leste'}, inplace=True)\n",
    "\n",
    "\n",
    "North_America = ['United States', 'Canada', 'Mexico',  'Bahamas', 'Barbados','Costa Rica', 'Grenada', 'Guadeloupe','Honduras', 'Panama', 'Puerto Rico',\n",
    "                 'Jamaica', 'Martinique']\n",
    "\n",
    "South_America = ['Argentina', 'Brazil', 'Chile','Colombia','Cuba','Ecuador','French Guiana', 'Paraguay', 'Peru', 'Suriname', \n",
    "                 'Trinidad and Tobago', 'Uruguay', 'Venezuela']\n",
    "\n",
    "Europe = ['Albania', 'Austria', 'Belarus', 'Belgium', 'Bosnia and Herzegovina', 'Bulgaria', 'Croatia', 'Cyprus',\n",
    "                 'Czech Republic', 'Denmark', 'Estonia', 'Faroe Islands', 'Finland', 'France', 'Georgia', 'Germany', \n",
    "                 'Greece', 'Hungary', 'Iceland', 'Ireland', 'Italy', 'Latvia', 'Liechtenstein', 'Lithuania',\n",
    "                 'Luxembourg', 'Macedonia', 'Malta', 'Moldova', 'Montenegro', 'Netherlands', 'Norway', 'Poland',\n",
    "                 'Portugal', 'Romania', 'Russia', 'San Marino', 'Serbia', 'Slovakia', 'Slovenia', 'Spain',\n",
    "                 'Sweden', 'Switzerland','Turkey', 'Ukraine', 'United Kingdom']\n",
    "\n",
    "Asia = [ 'Armenia', 'Azerbaijan', 'Bahrain', 'Bangladesh','Cambodia','China', 'Hong Kong', 'India',  'Japan', 'Jordan','Kazakhstan',\n",
    "        'Indonesia', 'Iran', 'Iraq', 'Israel', 'Kuwait', 'Laos','Lebanon', 'Macau', 'Malaysia', 'Mongolia', 'Myanmar', 'Nepal', 'North Korea', \n",
    "        'Oman', 'Pakistan', 'Palestine', 'Philippines', 'Qatar', 'Saudi Arabia', 'Singapore', 'South Korea','Sri Lanka', 'Syria',\n",
    "        'Taiwan', 'Tajikistan','Thailand', 'Timor Leste','United Arab Emirates', 'Uzbekistan', 'Vietnam', 'Yemen']\n",
    "\n",
    "Oceania = [ 'Australia', 'Fiji','French Polynesia', 'New Zealand', 'Papua New Guinea']\n",
    "\n",
    "Africa = ['Algeria','Angola','Benin','Botswana', 'Brazzaville','Burkina Faso','Burundi', 'Cameroon',\n",
    "          'Chad',\"Cote d'Ivoire\", 'Democratic Republic Congo', 'Egypt', 'Ethiopia', 'Gabon', 'Ghana', 'Kenya',\n",
    "         'Lesotho', 'Liberia', 'Libya', 'Madagascar', 'Malawi', 'Mali', 'Mauritius', 'Morocco','Mozambique',\n",
    "          'Namibia', 'Niger', 'Nigeria', 'Rwanda', 'Senegal', 'Sierra Leone', 'Somalia', 'South Africa', 'Sudan',\n",
    "          'Tanzania', 'Togo','Tunisia', 'Uganda', 'Zambia','Zimbabwe']\n",
    "\n",
    "country_list = North_America + South_America + Europe + Asia + Oceania + Africa\n",
    "\n",
    "df_Authors = df_Authors[df_Authors.Country.isin (country_list)]\n",
    "\n",
    "def continent_ (a):\n",
    "    if a in Oceania:\n",
    "        return 'Oceania'\n",
    "    elif a in North_America:\n",
    "        return 'North_America'\n",
    "    elif a in South_America:\n",
    "        return 'South_America'\n",
    "    elif a in Asia:\n",
    "        return 'Asia'\n",
    "    elif a in Africa:\n",
    "        return 'Africa'\n",
    "    elif a in Europe:\n",
    "        return 'Europe'\n",
    "    else:\n",
    "        return 'NONE'\n",
    "\n",
    "df_Authors['Continent'] = df_Authors.Country.apply(lambda x: continent_(x))\n",
    "\n",
    "\n",
    "df_world = df_my_data.merge(df_Authors, on = 'Author_ID', how = 'left')\n",
    "\n",
    "df_world = df_world[['EID', 'Author_ID', 'Year', 'Country_y', 'Continent']]\n",
    "df_world.rename(columns={'Country_y' : 'Country'}, inplace = True)\n",
    "\n",
    "df_world = df_world[~df_world.Country.isnull()]\n",
    "\n",
    "df_world.Year = df_world.Year.astype(int)\n",
    "\n",
    "df_LDA = pd.read_csv(r'C:\\Users\\moham\\Dropbox\\QSE\\Thesis\\Geopattern\\My data\\df_LDA.csv')\n",
    "df_LDA.set_index('EID', inplace = True)\n",
    "\n",
    "print ('Loading data from sql is done!')\n",
    "\n",
    "width_ind = 3\n",
    "width_dep = 2\n",
    "\n",
    "df_data_set = pd.DataFrame()\n",
    "\n",
    "list_years = []\n",
    "\n",
    "for yrs in range(1, 21 - width_ind - width_dep, 2):\n",
    "    list_years.append(2000 + yrs)\n",
    "\n",
    "\n",
    "for yr in tqdm(list_years, desc = 'Preparing the data set'):\n",
    "\n",
    "\n",
    "    Ind_win_start = yr\n",
    "    Ind_win_end = Ind_win_start + width_ind - 1\n",
    "\n",
    "    dep_win_start = Ind_win_end + 1\n",
    "    dep_win_end = dep_win_start + width_dep - 1\n",
    "\n",
    "    df_ind = df_world[(df_world.Year > (Ind_win_start - 1)) & (df_world.Year <= Ind_win_end)]\n",
    "    df_dep = df_world[(df_world.Year > (dep_win_start - 1)) & (df_world.Year <= dep_win_end)]\n",
    "\n",
    "\n",
    "    # Targets.................................................................................................. \n",
    "    \n",
    "#  For authors with at least one paper in the ind dataset\n",
    "\n",
    "#     df_dep.Author_ID = df_dep.Author_ID.astype('int64')\n",
    "#     df_ind.Author_ID = df_ind.Author_ID.astype('int64')\n",
    "\n",
    "#     set_authors_dep = set(df_dep.Author_ID.tolist())\n",
    "#     set_authors_ind = set(df_ind.Author_ID.tolist())\n",
    "\n",
    "\n",
    "#  For authors with at least more than one papers in the ind dataset\n",
    "\n",
    "    \n",
    "    df_count = df_ind.groupby('Author_ID').count()\n",
    "    df_count2 = df_count[df_count.EID > 1]\n",
    "    df_count2.reset_index (inplace = True)\n",
    "    df_count2.Author_ID = df_count2.Author_ID.astype('int64')\n",
    "    set_authors_ind = set(df_count2.Author_ID.tolist())\n",
    "\n",
    "    df_dep.Author_ID = df_dep.Author_ID.astype('int64')    \n",
    "    set_authors_dep = set(df_dep.Author_ID.tolist())\n",
    "    \n",
    "#  ---------------------------------------------------------------------------------\n",
    "    \n",
    "    list_authors = list(set_authors_dep.intersection(set_authors_ind))\n",
    "    list_authors.sort()\n",
    "\n",
    "\n",
    "    df_authors_dep = pd.DataFrame(data = list_authors, columns = ['Author_ID'])\n",
    "    \n",
    "    df_dep.Author_ID = df_dep.Author_ID.astype(str)\n",
    "    df_ind.Author_ID = df_ind.Author_ID.astype(str)\n",
    "    df_authors_dep.Author_ID = df_authors_dep.Author_ID.astype(str)\n",
    "    \n",
    "    df_authors_dep.insert(1,'EIDs','')\n",
    "\n",
    "    df_authors_dep = df_authors_dep.merge(df_Authors, on = 'Author_ID', how = 'left')\n",
    "\n",
    "    authors_dep = []\n",
    "    for i in range (df_authors_dep.shape[0]):\n",
    "        for j in range (df_authors_dep.shape[0]):\n",
    "            if j > i:\n",
    "                authors_dep.append((df_authors_dep['Author_ID'][i] + df_authors_dep['Author_ID'][j], df_authors_dep['Author_ID'][i], df_authors_dep['Author_ID'][j]))\n",
    "\n",
    "    df_data_set_dep = pd.DataFrame(data = authors_dep, columns=['Author_1_2', 'Author_1', 'Author_2'])\n",
    "\n",
    "    df_data_set_dep = df_data_set_dep.set_index(['Author_1_2'])\n",
    "\n",
    "    df_data_set_dep.insert(2,'number_of_collaborations',0)\n",
    "    df_data_set_dep.insert(3,'collaboration_binary',0)\n",
    "\n",
    "    df_dep.reset_index(inplace = True)\n",
    "\n",
    "    df_authors_dep['EIDs'] = ''\n",
    "    for i in range (df_authors_dep.shape[0]):\n",
    "        for j in range (df_dep.shape[0]):\n",
    "            if df_authors_dep['Author_ID'][i] == df_dep['Author_ID'][j]:\n",
    "                df_authors_dep['EIDs'][i] = str (df_authors_dep['EIDs'][i]) + ';' + str (df_dep['EID'][j])\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for i in range (df_authors_dep.shape[0]):\n",
    "        l = df_authors_dep['EIDs'][i].split(';')\n",
    "        l.remove('')\n",
    "        res.append((df_authors_dep['Author_ID'][i],set(l)))\n",
    "\n",
    "\n",
    "    collab_matrix = np.zeros((df_authors_dep.shape[0],df_authors_dep.shape[0]))\n",
    "\n",
    "    for i in range (len(res)):\n",
    "        for j in range (len(res)):\n",
    "            collab_matrix[i,j] = len(res[i][1].intersection(res[j][1]))\n",
    "\n",
    "    collab_list = []\n",
    "    for i in range (collab_matrix.shape[0]):\n",
    "        for j in range (collab_matrix.shape[0]):\n",
    "            if j > i:\n",
    "                if collab_matrix[i,j] != 0:\n",
    "                    collab_list.append((df_authors_dep['Author_ID'][i] + df_authors_dep['Author_ID'][j], df_authors_dep['Author_ID'][i], df_authors_dep['Author_ID'][j], collab_matrix[i,j]))\n",
    "\n",
    "    df_collab = pd.DataFrame(data = collab_list, columns=['Author_1_2', 'Author_1', 'Author_2', 'number_of_collaborations'])\n",
    "\n",
    "    df_collab['collaboration_binary'] = df_collab.number_of_collaborations.map(lambda x: 1 if x > 0 else 0)\n",
    "    \n",
    "    print(f'{dep_win_start} to {dep_win_end} : Authors: {len(set(df_authors_dep.Author_ID.unique().tolist()))} collaborations: {df_collab.collaboration_binary.sum()}')\n",
    "    \n",
    "    df_collab = df_collab.set_index(['Author_1_2'])\n",
    "\n",
    "    for i in df_data_set_dep.index:\n",
    "        try:\n",
    "            df_data_set_dep.loc[i,'number_of_collaborations'] = df_collab.loc[i,'number_of_collaborations']\n",
    "        except:\n",
    "            df_data_set_dep.loc[i,'number_of_collaborations'] = 0\n",
    "\n",
    "\n",
    "    df_data_set_dep.collaboration_binary = df_data_set_dep.number_of_collaborations.map(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "\n",
    "    # Features............................................................................................\n",
    "\n",
    "    df_authors_ind = pd.DataFrame(data = list_authors, columns = ['Author_ID'])\n",
    "    \n",
    "    df_authors_ind.Author_ID = df_authors_ind.Author_ID.astype(str)\n",
    "\n",
    "    df_authors_ind.insert(1,'EIDs','')\n",
    "    df_authors_ind.insert(2,'partners',0)\n",
    "    df_authors_ind.insert(3,'topic_1',0)\n",
    "    df_authors_ind.insert(4,'topic_2',0)\n",
    "    df_authors_ind.insert(5,'topic_3',0)\n",
    "    df_authors_ind.insert(6,'topic_4',0)\n",
    "    df_authors_ind.insert(7,'topic_5',0)\n",
    "    df_authors_ind.insert(8,'topic_6',0)\n",
    "    df_authors_ind.insert(9,'topic_7',0)\n",
    "    df_authors_ind.insert(10,'topic_8',0)\n",
    "    df_authors_ind.insert(11,'topic_9',0)\n",
    "\n",
    "\n",
    "    df_authors_ind = df_authors_ind.merge(df_Authors, on = 'Author_ID', how = 'left')\n",
    "\n",
    "    df_authors_ind.reset_index(inplace = True)\n",
    "    df_ind.reset_index(inplace = True)\n",
    "\n",
    "    df_authors_ind['EIDs'] = ''\n",
    "\n",
    "    for i in range (df_authors_ind.shape[0]):\n",
    "        for j in range (df_ind.shape[0]):\n",
    "            if df_authors_ind['Author_ID'][i] == df_ind['Author_ID'][j]:\n",
    "                df_authors_ind['EIDs'][i] = str (df_authors_ind['EIDs'][i]) + ';' + str (df_ind['EID'][j])\n",
    "                df_authors_ind.loc[i, 'topic_1'] += df_LDA.loc[str (df_ind['EID'][j]), 'topic_1']\n",
    "                df_authors_ind.loc[i, 'topic_2'] += df_LDA.loc[str (df_ind['EID'][j]), 'topic_2']\n",
    "                df_authors_ind.loc[i, 'topic_3'] += df_LDA.loc[str (df_ind['EID'][j]), 'topic_3']\n",
    "                df_authors_ind.loc[i, 'topic_4'] += df_LDA.loc[str (df_ind['EID'][j]), 'topic_4']\n",
    "                df_authors_ind.loc[i, 'topic_5'] += df_LDA.loc[str (df_ind['EID'][j]), 'topic_5']\n",
    "                df_authors_ind.loc[i, 'topic_6'] += df_LDA.loc[str (df_ind['EID'][j]), 'topic_6']\n",
    "                df_authors_ind.loc[i, 'topic_7'] += df_LDA.loc[str (df_ind['EID'][j]), 'topic_7']\n",
    "                df_authors_ind.loc[i, 'topic_8'] += df_LDA.loc[str (df_ind['EID'][j]), 'topic_8']\n",
    "                df_authors_ind.loc[i, 'topic_9'] += df_LDA.loc[str (df_ind['EID'][j]), 'topic_9']\n",
    "\n",
    "    for i in range (df_authors_ind.shape[0]):\n",
    "        summ = df_authors_ind.loc[i,'topic_1'] + df_authors_ind.loc[i,'topic_2'] + df_authors_ind.loc[i,'topic_3'] + df_authors_ind.loc[i,'topic_4'] + df_authors_ind.loc[i,'topic_5'] + df_authors_ind.loc[i,'topic_6'] + df_authors_ind.loc[i,'topic_7'] + df_authors_ind.loc[i,'topic_8'] + df_authors_ind.loc[i,'topic_9']\n",
    "        if summ > 0:\n",
    "            df_authors_ind.loc[i,'topic_1'] = df_authors_ind.loc[i,'topic_1']/summ\n",
    "            df_authors_ind.loc[i,'topic_2'] = df_authors_ind.loc[i,'topic_2']/summ\n",
    "            df_authors_ind.loc[i,'topic_3'] = df_authors_ind.loc[i,'topic_3']/summ\n",
    "            df_authors_ind.loc[i,'topic_4'] = df_authors_ind.loc[i,'topic_4']/summ\n",
    "            df_authors_ind.loc[i,'topic_5'] = df_authors_ind.loc[i,'topic_5']/summ\n",
    "            df_authors_ind.loc[i,'topic_6'] = df_authors_ind.loc[i,'topic_6']/summ\n",
    "            df_authors_ind.loc[i,'topic_7'] = df_authors_ind.loc[i,'topic_7']/summ\n",
    "            df_authors_ind.loc[i,'topic_8'] = df_authors_ind.loc[i,'topic_8']/summ\n",
    "            df_authors_ind.loc[i,'topic_9'] = df_authors_ind.loc[i,'topic_9']/summ\n",
    "\n",
    "    res = []\n",
    "\n",
    "    for i in range (df_authors_ind.shape[0]):\n",
    "        l = df_authors_ind['EIDs'][i].split(';')\n",
    "        l.remove('')\n",
    "        res.append((df_authors_ind['Author_ID'][i],set(l)))\n",
    "\n",
    "\n",
    "    collab_matrix = np.zeros((df_authors_ind.shape[0],df_authors_ind.shape[0]))\n",
    "\n",
    "    for i in range (len(res)):\n",
    "        for j in range (len(res)):\n",
    "            collab_matrix[i,j] = len(res[i][1].intersection(res[j][1]))\n",
    "\n",
    "    collab_list = []\n",
    "    for i in range (collab_matrix.shape[0]):\n",
    "        for j in range (collab_matrix.shape[0]):\n",
    "            if j > i:\n",
    "                if collab_matrix[i,j] != 0:\n",
    "                    collab_list.append((df_authors_ind['Author_ID'][i] + df_authors_ind['Author_ID'][j], df_authors_ind['Author_ID'][i], df_authors_ind['Author_ID'][j], collab_matrix[i,j]))\n",
    "\n",
    "    df_collab = pd.DataFrame(data = collab_list, columns=['Author_1_2', 'Author_1', 'Author_2', 'number_of_collaborations'])\n",
    "\n",
    "\n",
    "    df_collab = df_collab.set_index(['Author_1_2'])\n",
    "\n",
    "    df_authors_ind ['partners'] = ''\n",
    "    for i in range (collab_matrix.shape[0]):\n",
    "        for j in range (collab_matrix.shape[0]):\n",
    "            if i != j:\n",
    "                if collab_matrix[i,j] != 0:\n",
    "                    df_authors_ind ['partners'][i] = str (df_authors_ind ['partners'][i]) + ';' + str (df_authors_ind ['Author_ID'][j])\n",
    "\n",
    "\n",
    "    df_data_set_ind = pd.DataFrame(data = authors_dep, columns=['Author_1_2', 'Author_1', 'Author_2'])\n",
    "\n",
    "    df_data_set_ind = df_data_set_ind.set_index(['Author_1_2'])\n",
    "\n",
    "    df_data_set_ind.insert(2,'TENB',0)\n",
    "    df_data_set_ind.insert(3,'Cog_Dist', '')\n",
    "    df_data_set_ind.insert(4,'Geo_Dist',0)\n",
    "    df_data_set_ind.insert(5,'Diff_Country',0)\n",
    "    df_data_set_ind.insert(6,'Diff_Continent',0)\n",
    "    df_data_set_ind.insert(7,'Not_Contig',0)\n",
    "\n",
    "    # TENB\n",
    "\n",
    "    res_p = []\n",
    "\n",
    "    for i in range (df_authors_ind.shape[0]):\n",
    "        l = df_authors_ind['partners'][i].split(';')\n",
    "        l.remove('')\n",
    "        res_p.append((df_authors_ind['Author_ID'][i],set(l)))\n",
    "\n",
    "    common_partners_matrix = np.zeros((df_authors_ind.shape[0],df_authors_ind.shape[0]))\n",
    "\n",
    "    for i in range (len(res_p)):\n",
    "        for j in range (len(res_p)):\n",
    "            common_partners_matrix[i,j] = len(res_p[i][1].intersection(res_p[j][1]))\n",
    "\n",
    "\n",
    "    df_common_partners = pd.DataFrame([])\n",
    "    df_common_partners.insert(0,'Author_1_2','')\n",
    "    df_common_partners.insert(1,'Author_1','')\n",
    "    df_common_partners.insert(2,'Author_2','')\n",
    "    df_common_partners.insert(3,'Common_partners',{})\n",
    "    df_common_partners.insert(4,'TENB',float)\n",
    "\n",
    "\n",
    "    for i in range (common_partners_matrix.shape[0]):\n",
    "        for j in range (common_partners_matrix.shape[0]):\n",
    "            if j > i:\n",
    "                if common_partners_matrix[i,j] != 0:\n",
    "                    df_common_partners = df_common_partners.append({'Author_1_2': df_authors_ind['Author_ID'][i] + df_authors_ind['Author_ID'][j],'Author_1': df_authors_ind['Author_ID'][i], 'Author_2': df_authors_ind['Author_ID'][j], 'Common_partners': res_p[i][1].intersection(res_p[j][1])}, ignore_index = True)\n",
    "\n",
    "\n",
    "    number_of_articles = []\n",
    "    for i in range (collab_matrix.shape[0]):\n",
    "        number_of_articles.append((df_authors_ind['Author_ID'][i], collab_matrix[i,i]))\n",
    "\n",
    "    df_number_of_articles = pd.DataFrame(data = number_of_articles, columns=['Author', 'number_of_articles'])\n",
    "\n",
    "    df_number_of_articles_ = df_number_of_articles.set_index(['Author'])\n",
    "\n",
    "    df_collab_ = df_collab.set_index(['Author_1' , 'Author_2'])\n",
    "\n",
    "    for i in range (df_common_partners.shape[0]):\n",
    "        n = len(df_common_partners['Common_partners'][i])\n",
    "        list_ENB = []\n",
    "        for j in range (n):\n",
    "            common_partner = list (df_common_partners['Common_partners'][i])[j]\n",
    "            d = df_number_of_articles_.loc[common_partner,'number_of_articles']\n",
    "            num_article_common_partner = int(d)\n",
    "            Auth_1 = df_common_partners['Author_1'][i]\n",
    "            try:\n",
    "                x = df_collab_.loc[(Auth_1,common_partner),'number_of_collaborations']\n",
    "            except KeyError:\n",
    "                x = 0\n",
    "            if x != 0:\n",
    "                num_collab_Auth_1 = x\n",
    "            else:\n",
    "                num_collab_Auth_1 = df_collab_.loc[(common_partner,Auth_1),'number_of_collaborations']\n",
    "            Auth_2 = df_common_partners['Author_2'][i]\n",
    "            try:\n",
    "                y = df_collab_.loc[(Auth_2,common_partner),'number_of_collaborations']\n",
    "            except KeyError:\n",
    "                y = 0\n",
    "            if y != 0:\n",
    "                num_collab_Auth_2 = y\n",
    "            else:\n",
    "                num_collab_Auth_2 = df_collab_.loc[(common_partner,Auth_2),'number_of_collaborations']\n",
    "            ENB = ((int(num_collab_Auth_1)) * (int(num_collab_Auth_2))) / num_article_common_partner\n",
    "            list_ENB.append(ENB)\n",
    "            TENB = sum(list_ENB)\n",
    "        df_common_partners['TENB'][i] = TENB\n",
    "\n",
    "    df_common_partners = df_common_partners.set_index(['Author_1_2'])\n",
    "\n",
    "    for i in df_common_partners.index:\n",
    "        df_data_set_ind.loc[i,'TENB'] = df_common_partners.loc[i,'TENB']\n",
    "\n",
    "    df_authors_ind = df_authors_ind.set_index('Author_ID')\n",
    "\n",
    "\n",
    "    #Cog_Dist\n",
    "\n",
    "    for i in df_data_set_ind.index:\n",
    "        a1 = df_authors_ind.loc[df_data_set_ind.loc[i, 'Author_1'], ['topic_1', 'topic_2', 'topic_3', 'topic_4','topic_5', 'topic_6','topic_7', 'topic_8','topic_9']]\n",
    "        a1=a1.tolist()\n",
    "        a2 = df_authors_ind.loc[df_data_set_ind.loc[i, 'Author_2'], ['topic_1', 'topic_2', 'topic_3', 'topic_4','topic_5', 'topic_6','topic_7', 'topic_8','topic_9']]\n",
    "        a2=a2.tolist()\n",
    "        if a1 != [0,0,0,0,0,0,0,0,0] and a2 != [0,0,0,0,0,0,0,0,0]:\n",
    "            cor = numpy.corrcoef(a1, a2)\n",
    "            df_data_set_ind.loc[i, 'Cog_Dist'] = 1 - cor[0][1]\n",
    "\n",
    "    # Geo_Dist\n",
    "\n",
    "    import math\n",
    "\n",
    "    def Geo_Distance (lat_1,lon_1,lat_2,lon_2):\n",
    "        R = 6373.0\n",
    "        lat1 = math.radians(lat_1)\n",
    "        lon1 = math.radians(lon_1)\n",
    "        lat2 = math.radians(lat_2)\n",
    "        lon2 = math.radians(lon_2)\n",
    "        dlon = lon2 - lon1\n",
    "        dlat = lat2 - lat1\n",
    "        a = math.sin(dlat / 2)**2 + math.cos(lat1) * math.cos(lat2) * math.sin(dlon / 2)**2\n",
    "        c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "        distance = R * c\n",
    "        return distance\n",
    "\n",
    "    dist = []\n",
    "\n",
    "    for i in df_data_set_ind.index:\n",
    "        author_1 = df_data_set_ind.Author_1[i]\n",
    "        author_2 = df_data_set_ind.Author_2[i]\n",
    "        auth_1_lat = df_authors_ind.Latitude[author_1]\n",
    "        auth_1_lng = df_authors_ind.Longitude[author_1]\n",
    "        auth_2_lat = df_authors_ind.Latitude[author_2]\n",
    "        auth_2_lng = df_authors_ind.Longitude[author_2]\n",
    "\n",
    "        dist.append((author_1, author_2, Geo_Distance(auth_1_lat,auth_1_lng,auth_2_lat,auth_2_lng)))\n",
    "\n",
    "    df_geo_dist = pd.DataFrame(data = dist, columns=['Author_1', 'Author_2', 'GeoDist'])\n",
    "\n",
    "    df_geo_dist.insert(3,'Author_1_2','')\n",
    "\n",
    "    df_geo_dist.Author_1_2 = df_geo_dist.Author_1 + df_geo_dist.Author_2\n",
    "\n",
    "    df_geo_dist.set_index('Author_1_2', inplace = True)\n",
    "\n",
    "    df_data_set_ind.Geo_Dist = df_geo_dist.GeoDist\n",
    "\n",
    "    df_temp = pd.merge(df_data_set_ind, df_authors_ind, left_on = 'Author_1', right_index = True, how = 'left')\n",
    "    df_temp.rename({'Country_code':'Country_code_1'}, axis = 1, inplace = True)\n",
    "    df_temp.rename({'Continent':'Continent_1'}, axis = 1, inplace = True)\n",
    "    df_temp.drop(['EIDs','partners', 'Aff_ID', 'Latitude', 'Longitude', 'Province', 'Province_code'], axis = 1, inplace = True)\n",
    "    df_temp2 = pd.merge(df_temp, df_authors_ind, left_on = 'Author_2', right_index = True, how = 'left')\n",
    "    df_temp2.drop(['EIDs','partners', 'Aff_ID', 'Latitude', 'Longitude'], axis = 1, inplace = True)\n",
    "    df_temp2.rename({'Country_code':'Country_code_2'}, axis = 1, inplace = True)\n",
    "    df_temp2.rename({'Continent':'Continent_2'}, axis = 1, inplace = True)\n",
    "\n",
    "    def comparison_(x, y):\n",
    "        if x == y:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    df_temp2.Diff_Continent = df_temp2.apply(lambda x: comparison_(x.Continent_1, x.Continent_2), axis = 1)\n",
    "\n",
    "    df_data_set_ind.Diff_Continent = df_temp2.Diff_Continent\n",
    "    \n",
    "    df_temp2.Diff_Country = df_temp2.apply(lambda x: comparison_(x.Country_code_1, x.Country_code_2), axis = 1)\n",
    "\n",
    "    df_data_set_ind.Diff_Country = df_temp2.Diff_Country\n",
    "\n",
    "    list_prov = list(df_authors_ind.Province.unique())\n",
    "    \n",
    "    dic_contig = {'Albania':['Greece','Macedonia','Montenegro'],\n",
    "                     'Algeria':['Libya','Mali','Morocco','Niger','Tunisia'],\n",
    "                     'Angola':['Democratic Republic Congo','Namibia','Zambia'],\n",
    "                     'Argentina':['Bolivia','Brazil','Chile','Paraguay','Uruguay'],\n",
    "                     'Armenia':['Azerbaijan','Georgia','Iran','Turkey'],\n",
    "                     'Australia':[],\n",
    "                     'Austria':['Czech Republic','Germany','Hungary','Italy','Liechtenstein','Slovakia','Slovenia','Switzerland'],\n",
    "                     'Azerbaijan':['Armenia','Georgia','Iran','Russia','Turkey'],\n",
    "                     'Bahamas':[],\n",
    "                     'Bahrain':[],\n",
    "                     'Bangladesh':['India','Myanmar'],\n",
    "                     'Barbados' : [],\n",
    "                     'Belarus':['Latvia','Lithuania','Poland','Russia','Ukraine'],\n",
    "                     'Belgium':['France','Germany','Luxembourg','Netherlands'],\n",
    "                     'Benin':['Burkina Faso','Niger','Nigeria'],\n",
    "                     'Bosnia and Herzegovina':['Croatia','Montenegro','Serbia'],\n",
    "                     'Botswana':['Namibia','South Africa','Zambia','Zimbabwe'],\n",
    "                     'Brazil':['Argentina','Bolivia','Colombia','French Guiana','Paraguay','Peru','Suriname','Uruguay','Venezuela'],\n",
    "                     'Brazzaville':['Angola','Cameroon','Democratic Republic Congo','Gabon'],\n",
    "                     'Bulgaria':['Greece','Macedonia','Romania','Serbia','Turkey'],\n",
    "                     'Burkina Faso':['Benin',\"Cote d'Ivoire\", 'Ghana','Mali','Niger'],\n",
    "                     'Burundi':['Democratic Republic Congo','Rwanda','Tanzania'],\n",
    "                     'Cambodia':['Thailand','Vietnam'],\n",
    "                     'Cameroon':['Chad','Brazzaville','Gabon','Nigeria'],\n",
    "                     'Canada':['United States'],\n",
    "                     'Chile':['Argentina','Bolivia','Peru'],\n",
    "                     'China':['Hong Kong','India','Kazakhstan','North Korea','Macau','Mongolia','Myanmar','Nepal','Pakistan','Russia','Tajikistan','Vietnam'],\n",
    "                     'Colombia':['Brazil','Ecuador','Panama','Peru','Venezuela'],\n",
    "                     'Costa Rica':['Panama'],\n",
    "                     \"Cote d'Ivoire\":['Burkina Faso','Ghana','Liberia','Mali'],\n",
    "                     'Croatia':['Bosnia and Herzegovina','Hungary','Montenegro','Serbia','Slovenia'],\n",
    "                     'Cuba':[],\n",
    "                     'Cyprus':[],\n",
    "                     'Czech Republic':['Austria','Germany','Poland','Slovakia'],\n",
    "                     'Democratic Republic Congo':['Angola','Brazzaville','Rwanda','Tanzania','Uganda','Zambia', 'Burundi'],\n",
    "                     'Denmark':['Germany'],\n",
    "                     'Ecuador': ['Colombia','Peru'],\n",
    "                     'Egypt':['Palestine','Israel','Libya','Sudan'],\n",
    "                     'Estonia':['Latvia', 'Russia'],\n",
    "                     'Ethiopia':['Kenya','Somalia','Sudan'],\n",
    "                     'Faroe Islands':[],\n",
    "                     'Fiji':[],\n",
    "                     'Finland':['Norway','Sweden','Russia'],\n",
    "                     'France':['Belgium','Germany','Italy','Luxembourg','Monaco','Spain','Switzerland'],\n",
    "                     'French Guiana':['Brazil','Suriname'],\n",
    "                     'French Polynesia':[],\n",
    "                     'Georgia':['Armenia','Azerbaijan','Russia','Turkey'],\n",
    "                     'Germany':['Austria','Belgium','Czech Republic','Denmark','France','Luxembourg','Netherlands','Poland','Switzerland'],\n",
    "                     'Ghana':['Burkina Faso',\"Cote d'Ivoire\"],\n",
    "                     'Greece':['Albania','Bulgaria','Turkey','Macedonia'],\n",
    "                     'Grenada':[],\n",
    "                     'Guadeloupe':[],\n",
    "                     'Honduras':[],\n",
    "                     'Hong Kong':['Hong Kong'],\n",
    "                     'Hungary':['Austria','Croatia','Romania','Serbia','Slovakia','Slovenia','Ukraine'],\n",
    "                     'Iceland':[],\n",
    "                     'India':['Bangladesh','China','Myanmar','Nepal','Pakistan','Sri Lanka'],\n",
    "                     'Indonesia':['Timor Leste','Malaysia','Papua New Guinea'],\n",
    "                     'Iran':['Armenia','Azerbaijan','Iraq','Pakistan','Turkey'],\n",
    "                     'Iraq':['Iran','Jordan','Kuwait','Saudi Arabia','Syria','Turkey'],\n",
    "                     'Ireland':['United Kingdom'],\n",
    "                     'Israel':['Egypt','Palestine','Jordan','Lebanon','Syria','Palestine'],\n",
    "                     'Italy':['Austria','France','San Marino','Slovenia','Switzerland'],\n",
    "                     'Jamaica':[],\n",
    "                     'Japan':[],\n",
    "                     'Jordan':['Iraq','Israel','Saudi Arabia','Syria','Palestine'],\n",
    "                     'Kazakhstan':['China','Russia','Uzbekistan'],\n",
    "                     'Kenya':['Ethiopia','Somalia','Tanzania','Uganda'],\n",
    "                     'Kuwait':['Iraq','Saudi Arabia'],\n",
    "                     'Laos': ['Cambodia', 'China', 'Myanmar', 'Thailand' ,'Vietnam'],\n",
    "                     'Latvia':['Belarus','Estonia','Lithuania','Russia'],\n",
    "                     'Lebanon':['Israel','Syria'],\n",
    "                     'Lesotho':['South Africa'],\n",
    "                     'Liberia':[\"Cote d'Ivoire\",'Sierra Leone'],\n",
    "                     'Libya':['Algeria','Chad','Egypt','Niger','Sudan','Tunisia'],\n",
    "                     'Liechtenstein':['Austria','Switzerland'],\n",
    "                     'Lithuania':['Belarus','Latvia','Poland','Russia'],\n",
    "                     'Luxembourg':['Belgium','France','Germany'],\n",
    "                     'Macedonia':['Albania','Bulgaria','Greece','Serbia'],\n",
    "                     'Madagascar':[],\n",
    "                     'Malawi':['Mozambique','Tanzania','Zambia'],\n",
    "                     'Malaysia':['Brunei','Indonesia','Singapour','Thailand'],\n",
    "                     'Mali':['Algeria','Burkina Faso',\"Cote d'Ivoire\",'Niger','Senegal'],\n",
    "                     'Malta':[],\n",
    "                     'Martinique':[],\n",
    "                     'Mauritius': [],\n",
    "                     'Mexico':['United States'],\n",
    "                     'Moldova':['Romania','Ukraine'],\n",
    "                     'Mongolia':['China','Russia'],\n",
    "                     'Montenegro':['Albania','Bosnia and Herzegovina','Croatia','Serbia'],\n",
    "                     'Morocco':['Algeria','Spain'],\n",
    "                     'Mozambique':['Malawi','South Africa','Tanzania','Zambia','Zimbabwe'],\n",
    "                     'Myanmar':['Bangladesh','China','India','Thailand'],\n",
    "                     'Namibia':['Angola','Botswana','South Africa','Zambia'],\n",
    "                     'Nepal':['China','India'],\n",
    "                     'Netherlands':['Belgium'],\n",
    "                     'New Zealand':[],\n",
    "                     'Niger':['Algeria','Benin','Burkina Faso','Chad','Libya','Mali','Nigeria'],\n",
    "                     'Nigeria':['Benin','Cameroon','Chad','Niger'],\n",
    "                     'North Korea':['China','South Korea','Russia'],\n",
    "                     'Norway':['Finland','Sweden','Russia'],\n",
    "                     'Oman':['Saudi Arabia','United Arab Emirates','Yemen'],\n",
    "                     'Pakistan':['India','Iran','China'],\n",
    "                     'Panama':['Colombia', 'Costa Rica'],\n",
    "                     'Papua New Guinea':['Indonesia'],\n",
    "                     'Paraguay':['Argentina','Bolivia','Brazil'],\n",
    "                     'Peru':['Brazil','Chile','Colombia','Ecuador'],\n",
    "                     'Philippines':[],\n",
    "                     'Poland':['Belarus','Czech Republic','Germany','Lithuania','Russia','Slovakia','Ukraine'],\n",
    "                     'Portugal':['Spain'],\n",
    "                     'Puerto Rico':[],\n",
    "                     'Qatar':['Saudi Arabia'],\n",
    "                     'Romania':['Bulgaria','Hungary','Moldova','Serbia','Ukraine'],\n",
    "                     'Russia':['Azerbaijan','Belarus','China','Estonia','Finland','Georgia','Kazakhstan','North Korea','Latvia','Lithuania','Mongolia','Norway','Poland','Ukraine'],\n",
    "                     'Rwanda':['Democratic Republic Congo','Tanzania','Uganda','Burundi'],\n",
    "                     'San Marino':['Italy'],\n",
    "                     'Saudi Arabia':['Iraq','Jordan','Kuwait','Oman','Qatar','United Arab Emirates','Yemen'],\n",
    "                     'Senegal':['Mali'],\n",
    "                     'Serbia':['Bosnia and Herzegovina','Bulgaria','Croatia','Hungary','Montenegro','Macedonia','Romania'],\n",
    "                     'Sierra Leone':['Liberia'],\n",
    "                     'Singapore':['Malaysia'],\n",
    "                     'Slovakia':['Austria','Czech Republic','Hungary','Poland','Ukraine'],\n",
    "                     'Slovenia':['Austria','Croatia','Italy','Hungary'],\n",
    "                     'Somalia':['Ethiopia','Kenya'],\n",
    "                     'South Africa':['Botswana','Lesotho','Mozambique','Namibia','Zimbabwe'],\n",
    "                     'South Korea':['North Korea'],\n",
    "                     'Spain':['France','Portugal','Morocco'],\n",
    "                     'Sri Lanka':['India'],\n",
    "                     'Sudan':['Chad','Egypt','Ethiopia','Libya'],\n",
    "                     'Suriname':['Brazil','French Guiana'],\n",
    "                     'Sweden':['Finland','Norway'],\n",
    "                     'Switzerland':['Austria','France','Italy','Liechtenstein','Germany'],\n",
    "                     'Syria':['Iraq','Israel','Jordan','Lebanon','Turkey'],\n",
    "                     'Taiwan':[],\n",
    "                     'Tajikistan':['China','Uzbekistan'],\n",
    "                     'Tanzania':['Democratic Republic Congo','Kenya','Malawi','Mozambique','Rwanda','Uganda','Zambia','Burundi'],\n",
    "                     'Thailand':['Cambodia','Malaysia','Myanmar'],\n",
    "                     'Timor Leste':['Indonesia'],\n",
    "                     'Togo': ['Benin', 'Burkina Faso', 'Ghana'],\n",
    "                     'Trinidad and Tobago':[],\n",
    "                     'Tunisia':['Algeria','Libya'],\n",
    "                     'Turkey':['Armenia','Azerbaijan','Bulgaria','Georgia','Greece','Iran','Iraq','Syria'],\n",
    "                     'Uganda':['Democratic Republic Congo','Kenya','Rwanda','Tanzania'],\n",
    "                     'Ukraine':['Belarus','Hungary','Moldova','Poland','Romania','Russia','Slovakia'],\n",
    "                     'United Arab Emirates':['Oman','Saudi Arabia'],\n",
    "                     'United Kingdom':['Ireland'],\n",
    "                     'United States':['Canada','Mexico'],\n",
    "                     'Uruguay':['Argentina','Brazil'],\n",
    "                     'Uzbekistan':['Kazakhstan','Tajikistan'],\n",
    "                     'Venezuela':['Brazil','Colombia'],\n",
    "                     'Vietnam':['Cambodia', 'China'],\n",
    "                     'Yemen':['Oman','Saudi Arabia'],\n",
    "                     'Zambia':['Angola','Botswana','Malawi','Mozambique','Namibia','Tanzania','Zimbabwe'],\n",
    "                     'Zimbabwe':['Botswana','Mozambique','South Africa','Zambia']}\n",
    "\n",
    "    df_temp = pd.merge(df_data_set_ind, df_authors_ind, left_on = 'Author_1', right_index = True, how = 'left')\n",
    "    df_temp.rename({'Country':'Country_1'}, axis = 1, inplace = True)\n",
    "    df_temp.drop(['EIDs','partners', 'Aff_ID', 'Latitude', 'Longitude'], axis = 1, inplace = True)\n",
    "    df_temp2 = pd.merge(df_temp, df_authors_ind, left_on = 'Author_2', right_index = True, how = 'left')\n",
    "    df_temp2.drop(['EIDs','partners', 'Aff_ID', 'Latitude', 'Longitude'], axis = 1, inplace = True)\n",
    "    df_temp2.rename({'Country':'Country_2'}, axis = 1, inplace = True)\n",
    "\n",
    "    def contiguity_(x, y):\n",
    "        c = dic_contig[x]\n",
    "        if c.count(y) == 1:\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    df_temp2.Not_Contig = df_temp2.apply(lambda x: contiguity_(x.Country_1, x.Country_2), axis = 1)\n",
    "\n",
    "    df_data_set_ind.Not_Contig = df_temp2.Not_Contig\n",
    "\n",
    "        # Country dummies\n",
    "\n",
    "    one_hot = pd.get_dummies(df_temp2[['Country_1','Country_2']])\n",
    "    df_data_set_ind = df_data_set_ind.join(one_hot)\n",
    "\n",
    "    df_data_set_ = df_data_set_dep.merge(df_data_set_ind, right_index = True, left_index = True, how = 'left')\n",
    "    df_data_set = pd.concat([df_data_set,df_data_set_])\n",
    "\n",
    "    \n",
    "df_data_set.reset_index(inplace = True)\n",
    "df_data_set.drop(['Author_1_y', 'Author_2_y'], axis = 1, inplace = True)\n",
    "df_data_set.rename({'Author_1_x' : 'Author_1'}, axis = 1, inplace = True)\n",
    "df_data_set.rename({'Author_2_x' : 'Author_2'}, axis = 1, inplace = True)\n",
    "df_data_set.fillna(0, inplace = True)\n",
    "\n",
    "\n",
    "# def Top_regions (reg1, reg2):\n",
    "#     if reg1 == 1 and reg2 == 1:\n",
    "#         return 1\n",
    "        \n",
    "# df_data_set['Top_regions'] = df_data_set.apply(lambda x: Top_regions(x.Country_1_Germany, x.Country_2_Germany), axis = 1)\n",
    "# df_data_set['Top_regions'] = df_data_set.apply(lambda x: Top_regions(x['Country_1_United Kingdom'], x['Country_2_United Kingdom']), axis = 1)\n",
    "# df_data_set['Top_regions'] = df_data_set.apply(lambda x: Top_regions(x['Country_1_United States'], x['Country_2_United States']), axis = 1)\n",
    "\n",
    "# df_data_set['Top_regions'] = df_data_set.apply(lambda x: Top_regions(x.Country_1_Germany, x['Country_2_United Kingdom']), axis = 1)\n",
    "# df_data_set['Top_regions'] = df_data_set.apply(lambda x: Top_regions(x['Country_1_United Kingdom'], x.Country_2_Germany), axis = 1)\n",
    "\n",
    "# df_data_set['Top_regions'] = df_data_set.apply(lambda x: Top_regions(x.Country_1_Germany, x['Country_2_United States']), axis = 1)\n",
    "# df_data_set['Top_regions'] = df_data_set.apply(lambda x: Top_regions(x['Country_1_United States'], x.Country_2_Germany), axis = 1)\n",
    "\n",
    "# df_data_set['Top_regions'] = df_data_set.apply(lambda x: Top_regions(x['Country_1_United Kingdom'], x['Country_2_United States']), axis = 1)\n",
    "# df_data_set['Top_regions'] = df_data_set.apply(lambda x: Top_regions(x['Country_1_United States'], x['Country_2_United Kingdom']), axis = 1)\n",
    "\n",
    "# df_data_set['Top_regions'].fillna(0, inplace = True)\n",
    "\n",
    "df_data_set['Log_Geo_Dist'] = df_data_set.Geo_Dist.apply(lambda x :math.log1p(x))\n",
    "df_data_set['Log_TENB'] = df_data_set.TENB.apply(lambda x :math.log1p(x))\n",
    "df_data_set['Log_Geo_Dist X Log_TENB'] = df_data_set['Log_Geo_Dist'] * df_data_set['Log_TENB']\n",
    "df_data_set['Log_Geo_Dist_Sq'] = df_data_set['Log_Geo_Dist'] * df_data_set['Log_Geo_Dist']\n",
    "df_data_set['Log_Geo_Dist_Sq X Log_TENB'] = df_data_set['Log_Geo_Dist_Sq'] * df_data_set['Log_TENB']\n",
    "\n",
    "df_data_set.to_csv(r'C:\\Users\\moham\\Dropbox\\QSE\\Thesis\\Geopattern\\My data\\df_data_set_world2a.csv')\n",
    "# df_data_set.to_csv(r'C:\\Users\\moham\\Dropbox\\QSE\\Thesis\\Geopattern\\My data\\df_data_set_world1a.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c21c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data_set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
